{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNbjfFEcOH0b0y0hRJlTMO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rianachatterjee04/GenAssist/blob/main/Navigation_Zone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing dependencies"
      ],
      "metadata": {
        "id": "f2kIEsbrJ9_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "!pip install yt-dlp\n",
        "\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l1SkIZFyJ-1P",
        "outputId": "9c5e9e9a-4415-4961-8a76-dbfca090fbfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.73-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.73-py3-none-any.whl (914 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.6/914.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.73 ultralytics-thop-2.0.14\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.1.26-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.1.26-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.1.26\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup and Video Download"
      ],
      "metadata": {
        "id": "4Fqh0Y-uKBNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Create videos directory\n",
        "os.makedirs(\"videos\", exist_ok=True)\n",
        "\n",
        "# Download video\n",
        "VIDEO_URL = \"https://www.youtube.com/watch?v=RFb6wbsffY0\"\n",
        "!yt-dlp -o \"videos/NY_walk.%(ext)s\" {VIDEO_URL}  # Simplified filename\n",
        "\n",
        "# Find the downloaded video file\n",
        "video_path = glob.glob(\"videos/NY_walk.*\")[0]  # Get the first matching file\n",
        "print(f\"Video downloaded to: {video_path}\")\n",
        "\n",
        "# Get absolute path\n",
        "abs_path = os.path.abspath(video_path)\n",
        "print(f\"Absolute path: {abs_path}\")\n",
        "\n",
        "# Verify file exists\n",
        "if os.path.exists(video_path):\n",
        "    print(\"✅ Video file exists!\")\n",
        "    print(f\"File size: {os.path.getsize(video_path) / (1024*1024):.2f} MB\")\n",
        "else:\n",
        "    print(\"❌ Video file NOT found. Check the file name and location.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je1V-yz_KD2p",
        "outputId": "0c36df73-4e29-44ed-a179-be5fc101d62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=RFb6wbsffY0\n",
            "[youtube] RFb6wbsffY0: Downloading webpage\n",
            "[youtube] RFb6wbsffY0: Downloading tv client config\n",
            "[youtube] RFb6wbsffY0: Downloading player 9c6dfc4a\n",
            "[youtube] RFb6wbsffY0: Downloading tv player API JSON\n",
            "[youtube] RFb6wbsffY0: Downloading ios player API JSON\n",
            "[youtube] RFb6wbsffY0: Downloading m3u8 information\n",
            "[info] RFb6wbsffY0: Downloading 1 format(s): 315+251\n",
            "[download] videos/NY_walk.webm has already been downloaded\n",
            "Video downloaded to: videos/NY_walk.webm\n",
            "Absolute path: /content/videos/NY_walk.webm\n",
            "✅ Video file exists!\n",
            "File size: 1100.24 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting frames for analysis"
      ],
      "metadata": {
        "id": "nlKe0w44KGlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Find the downloaded video file\n",
        "video_path = glob.glob(\"videos/NY_walk.*\")[0]  # Use the same path from first script\n",
        "output_dir = \"frames\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Open video file\n",
        "vidcap = cv2.VideoCapture(video_path)\n",
        "if not vidcap.isOpened():\n",
        "    print(\"❌ Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "# Get video properties\n",
        "fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
        "total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "duration = total_frames / fps\n",
        "print(f\"Video FPS: {fps}\")\n",
        "print(f\"Total Frames: {total_frames}\")\n",
        "print(f\"Duration: {duration:.2f} seconds\")\n",
        "\n",
        "# Extract frames from 7s to 67s\n",
        "start_sec, end_sec = 7, 67\n",
        "start_frame = start_sec * fps\n",
        "end_frame = min(end_sec * fps, total_frames)\n",
        "\n",
        "vidcap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "frame_rate = 30\n",
        "count = 0\n",
        "\n",
        "while vidcap.isOpened():\n",
        "    frame_id = int(vidcap.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "    if frame_id > end_frame:\n",
        "        break\n",
        "\n",
        "    success, image = vidcap.read()\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    if frame_id % frame_rate == 0:\n",
        "        frame_name = os.path.join(output_dir, f\"frame_{frame_id}.jpg\")\n",
        "        cv2.imwrite(frame_name, image)\n",
        "        print(f\"✅ Saved: {frame_name}\")\n",
        "        count += 1\n",
        "\n",
        "vidcap.release()\n",
        "print(f\"✅ Extracted {count} frames\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hwDb-K58KID4",
        "outputId": "f225a491-b937-4a93-d9f4-f6b5728c8a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video FPS: 60\n",
            "Total Frames: 20344\n",
            "Duration: 339.07 seconds\n",
            "✅ Saved: frames/frame_420.jpg\n",
            "✅ Saved: frames/frame_450.jpg\n",
            "✅ Saved: frames/frame_480.jpg\n",
            "✅ Saved: frames/frame_510.jpg\n",
            "✅ Saved: frames/frame_540.jpg\n",
            "✅ Saved: frames/frame_570.jpg\n",
            "✅ Saved: frames/frame_600.jpg\n",
            "✅ Saved: frames/frame_630.jpg\n",
            "✅ Saved: frames/frame_660.jpg\n",
            "✅ Saved: frames/frame_690.jpg\n",
            "✅ Saved: frames/frame_720.jpg\n",
            "✅ Saved: frames/frame_750.jpg\n",
            "✅ Saved: frames/frame_780.jpg\n",
            "✅ Saved: frames/frame_810.jpg\n",
            "✅ Saved: frames/frame_840.jpg\n",
            "✅ Saved: frames/frame_870.jpg\n",
            "✅ Saved: frames/frame_900.jpg\n",
            "✅ Saved: frames/frame_930.jpg\n",
            "✅ Saved: frames/frame_960.jpg\n",
            "✅ Saved: frames/frame_990.jpg\n",
            "✅ Saved: frames/frame_1020.jpg\n",
            "✅ Saved: frames/frame_1050.jpg\n",
            "✅ Saved: frames/frame_1080.jpg\n",
            "✅ Saved: frames/frame_1110.jpg\n",
            "✅ Saved: frames/frame_1140.jpg\n",
            "✅ Saved: frames/frame_1170.jpg\n",
            "✅ Saved: frames/frame_1200.jpg\n",
            "✅ Saved: frames/frame_1230.jpg\n",
            "✅ Saved: frames/frame_1260.jpg\n",
            "✅ Saved: frames/frame_1290.jpg\n",
            "✅ Saved: frames/frame_1320.jpg\n",
            "✅ Saved: frames/frame_1350.jpg\n",
            "✅ Saved: frames/frame_1380.jpg\n",
            "✅ Saved: frames/frame_1410.jpg\n",
            "✅ Saved: frames/frame_1440.jpg\n",
            "✅ Saved: frames/frame_1470.jpg\n",
            "✅ Saved: frames/frame_1500.jpg\n",
            "✅ Saved: frames/frame_1530.jpg\n",
            "✅ Saved: frames/frame_1560.jpg\n",
            "✅ Saved: frames/frame_1590.jpg\n",
            "✅ Saved: frames/frame_1620.jpg\n",
            "✅ Saved: frames/frame_1650.jpg\n",
            "✅ Saved: frames/frame_1680.jpg\n",
            "✅ Saved: frames/frame_1710.jpg\n",
            "✅ Saved: frames/frame_1740.jpg\n",
            "✅ Saved: frames/frame_1770.jpg\n",
            "✅ Saved: frames/frame_1800.jpg\n",
            "✅ Saved: frames/frame_1830.jpg\n",
            "✅ Saved: frames/frame_1860.jpg\n",
            "✅ Saved: frames/frame_1890.jpg\n",
            "✅ Saved: frames/frame_1920.jpg\n",
            "✅ Saved: frames/frame_1950.jpg\n",
            "✅ Saved: frames/frame_1980.jpg\n",
            "✅ Saved: frames/frame_2010.jpg\n",
            "✅ Saved: frames/frame_2040.jpg\n",
            "✅ Saved: frames/frame_2070.jpg\n",
            "✅ Saved: frames/frame_2100.jpg\n",
            "✅ Saved: frames/frame_2130.jpg\n",
            "✅ Saved: frames/frame_2160.jpg\n",
            "✅ Saved: frames/frame_2190.jpg\n",
            "✅ Saved: frames/frame_2220.jpg\n",
            "✅ Saved: frames/frame_2250.jpg\n",
            "✅ Saved: frames/frame_2280.jpg\n",
            "✅ Saved: frames/frame_2310.jpg\n",
            "✅ Saved: frames/frame_2340.jpg\n",
            "✅ Saved: frames/frame_2370.jpg\n",
            "✅ Saved: frames/frame_2400.jpg\n",
            "✅ Saved: frames/frame_2430.jpg\n",
            "✅ Saved: frames/frame_2460.jpg\n",
            "✅ Saved: frames/frame_2490.jpg\n",
            "✅ Saved: frames/frame_2520.jpg\n",
            "✅ Saved: frames/frame_2550.jpg\n",
            "✅ Saved: frames/frame_2580.jpg\n",
            "✅ Saved: frames/frame_2610.jpg\n",
            "✅ Saved: frames/frame_2640.jpg\n",
            "✅ Saved: frames/frame_2670.jpg\n",
            "✅ Saved: frames/frame_2700.jpg\n",
            "✅ Saved: frames/frame_2730.jpg\n",
            "✅ Saved: frames/frame_2760.jpg\n",
            "✅ Saved: frames/frame_2790.jpg\n",
            "✅ Saved: frames/frame_2820.jpg\n",
            "✅ Saved: frames/frame_2850.jpg\n",
            "✅ Saved: frames/frame_2880.jpg\n",
            "✅ Saved: frames/frame_2910.jpg\n",
            "✅ Saved: frames/frame_2940.jpg\n",
            "✅ Saved: frames/frame_2970.jpg\n",
            "✅ Saved: frames/frame_3000.jpg\n",
            "✅ Saved: frames/frame_3030.jpg\n",
            "✅ Saved: frames/frame_3060.jpg\n",
            "✅ Saved: frames/frame_3090.jpg\n",
            "✅ Saved: frames/frame_3120.jpg\n",
            "✅ Saved: frames/frame_3150.jpg\n",
            "✅ Saved: frames/frame_3180.jpg\n",
            "✅ Saved: frames/frame_3210.jpg\n",
            "✅ Saved: frames/frame_3240.jpg\n",
            "✅ Saved: frames/frame_3270.jpg\n",
            "✅ Saved: frames/frame_3300.jpg\n",
            "✅ Saved: frames/frame_3330.jpg\n",
            "✅ Saved: frames/frame_3360.jpg\n",
            "✅ Saved: frames/frame_3390.jpg\n",
            "✅ Saved: frames/frame_3420.jpg\n",
            "✅ Saved: frames/frame_3450.jpg\n",
            "✅ Saved: frames/frame_3480.jpg\n",
            "✅ Saved: frames/frame_3510.jpg\n",
            "✅ Saved: frames/frame_3540.jpg\n",
            "✅ Saved: frames/frame_3570.jpg\n",
            "✅ Saved: frames/frame_3600.jpg\n",
            "✅ Saved: frames/frame_3630.jpg\n",
            "✅ Saved: frames/frame_3660.jpg\n",
            "✅ Saved: frames/frame_3690.jpg\n",
            "✅ Saved: frames/frame_3720.jpg\n",
            "✅ Saved: frames/frame_3750.jpg\n",
            "✅ Saved: frames/frame_3780.jpg\n",
            "✅ Saved: frames/frame_3810.jpg\n",
            "✅ Saved: frames/frame_3840.jpg\n",
            "✅ Saved: frames/frame_3870.jpg\n",
            "✅ Saved: frames/frame_3900.jpg\n",
            "✅ Saved: frames/frame_3930.jpg\n",
            "✅ Saved: frames/frame_3960.jpg\n",
            "✅ Saved: frames/frame_3990.jpg\n",
            "✅ Saved: frames/frame_4020.jpg\n",
            "✅ Extracted 121 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Safety Zone Detector"
      ],
      "metadata": {
        "id": "aa9L5TPhKLcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.plotting import Annotator, colors\n",
        "\n",
        "class SafetyZoneDetector:\n",
        "    def __init__(self):\n",
        "        self.model = YOLO(\"yolov8n-seg.pt\")\n",
        "        self.safety_classes = {\n",
        "            'sidewalk': {'type': 'safe', 'color': (0, 255, 0)},\n",
        "            'road': {'type': 'danger', 'color': (0, 0, 255)},\n",
        "            'person': {'type': 'dynamic', 'color': (255, 165, 0)},\n",
        "            'car': {'type': 'danger', 'color': (255, 0, 0)},\n",
        "            'bicycle': {'type': 'dynamic', 'color': (255, 165, 0)},\n",
        "            'traffic light': {'type': 'guide', 'color': (255, 255, 0)}\n",
        "        }\n",
        "\n",
        "    def draw_safety_zones(self, frame):\n",
        "        height, width = frame.shape[:2]\n",
        "        overlay = frame.copy()\n",
        "\n",
        "        # Navigation corridor\n",
        "        safe_zone_width = int(width * 0.6)\n",
        "        margin = (width - safe_zone_width) // 2\n",
        "        cv2.rectangle(overlay,\n",
        "                     (margin, height//3),\n",
        "                     (width-margin, height),\n",
        "                     (0, 255, 0),\n",
        "                     2)\n",
        "\n",
        "        # Add transparency\n",
        "        alpha = 0.3\n",
        "        frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
        "        return frame\n",
        "\n",
        "    def process_frame(self, frame):\n",
        "        processed = self.draw_safety_zones(frame.copy())\n",
        "        results = self.model.track(frame, persist=True)[0]\n",
        "\n",
        "        if results.boxes is not None and results.masks is not None:\n",
        "            boxes = results.boxes.xyxy.cpu().numpy()\n",
        "            classes = results.boxes.cls.cpu().numpy()\n",
        "            masks = results.masks.xy\n",
        "            track_ids = results.boxes.id.cpu().numpy() if results.boxes.id is not None else None\n",
        "\n",
        "            for i, (box, cls) in enumerate(zip(boxes, classes)):\n",
        "                class_name = self.model.names[int(cls)]\n",
        "                safety_info = self.safety_classes.get(\n",
        "                    class_name,\n",
        "                    {'type': 'unknown', 'color': (128, 128, 128)}\n",
        "                )\n",
        "\n",
        "                if i < len(masks):\n",
        "                    mask = masks[i]\n",
        "                    cv2.fillPoly(processed,\n",
        "                                [np.int32(mask)],\n",
        "                                safety_info['color'],\n",
        "                                lineType=cv2.LINE_AA)\n",
        "\n",
        "                track_id = int(track_ids[i]) if track_ids is not None else -1\n",
        "                label = f\"ID {track_id} - {class_name} ({safety_info['type']})\"\n",
        "                cv2.putText(processed,\n",
        "                           label,\n",
        "                           (int(box[0]), int(box[1])-10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                           0.6,\n",
        "                           safety_info['color'],\n",
        "                           2)\n",
        "\n",
        "        return processed\n"
      ],
      "metadata": {
        "id": "FIW6LPnbKOBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process frames according to safety analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "49yyeq4GKQmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "os.makedirs(\"safety_processed_frames\", exist_ok=True)\n",
        "detector = SafetyZoneDetector()\n",
        "\n",
        "# Process each frame\n",
        "frames_dir = \"frames\"\n",
        "frame_files = sorted(os.listdir(frames_dir))\n",
        "for frame_file in frame_files:\n",
        "    # Read frame\n",
        "    frame_path = os.path.join(frames_dir, frame_file)\n",
        "    frame = cv2.imread(frame_path)\n",
        "\n",
        "    # Process with safety detection\n",
        "    processed_frame = detector.process_frame(frame)\n",
        "\n",
        "    # Save processed frame\n",
        "    output_path = os.path.join(\"safety_processed_frames\", frame_file)\n",
        "    cv2.imwrite(output_path, processed_frame)\n",
        "    print(f\"✅ Processed: {frame_file}\")\n",
        "\n",
        "print(\"✅ Completed safety processing\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkZe0HeTKSsM",
        "outputId": "5f88cd72-2216-4f99-b11d-133d50b21a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 6 cars, 1 bus, 1 traffic light, 204.1ms\n",
            "Speed: 5.3ms preprocess, 204.1ms inference, 70.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1020.jpg\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 bus, 1 truck, 184.8ms\n",
            "Speed: 4.6ms preprocess, 184.8ms inference, 30.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1050.jpg\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 179.0ms\n",
            "Speed: 4.5ms preprocess, 179.0ms inference, 30.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1080.jpg\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 189.5ms\n",
            "Speed: 4.4ms preprocess, 189.5ms inference, 22.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1110.jpg\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 181.3ms\n",
            "Speed: 4.6ms preprocess, 181.3ms inference, 26.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1140.jpg\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 188.4ms\n",
            "Speed: 4.1ms preprocess, 188.4ms inference, 28.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1170.jpg\n",
            "\n",
            "0: 384x640 1 car, 175.5ms\n",
            "Speed: 4.3ms preprocess, 175.5ms inference, 34.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1200.jpg\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 291.2ms\n",
            "Speed: 4.5ms preprocess, 291.2ms inference, 56.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1230.jpg\n",
            "\n",
            "0: 384x640 1 car, 273.3ms\n",
            "Speed: 4.4ms preprocess, 273.3ms inference, 35.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1260.jpg\n",
            "\n",
            "0: 384x640 1 person, 1 car, 2 books, 282.6ms\n",
            "Speed: 5.3ms preprocess, 282.6ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1290.jpg\n",
            "\n",
            "0: 384x640 1 person, 2 tvs, 1 book, 301.9ms\n",
            "Speed: 4.9ms preprocess, 301.9ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1320.jpg\n",
            "\n",
            "0: 384x640 1 umbrella, 1 tv, 192.4ms\n",
            "Speed: 4.2ms preprocess, 192.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1350.jpg\n",
            "\n",
            "0: 384x640 1 traffic light, 1 book, 178.1ms\n",
            "Speed: 4.4ms preprocess, 178.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1380.jpg\n",
            "\n",
            "0: 384x640 1 umbrella, 1 laptop, 1 book, 174.8ms\n",
            "Speed: 4.7ms preprocess, 174.8ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1410.jpg\n",
            "\n",
            "0: 384x640 1 car, 175.7ms\n",
            "Speed: 4.6ms preprocess, 175.7ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1440.jpg\n",
            "\n",
            "0: 384x640 1 person, 1 car, 175.6ms\n",
            "Speed: 4.5ms preprocess, 175.6ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1470.jpg\n",
            "\n",
            "0: 384x640 1 bus, 1 truck, 174.1ms\n",
            "Speed: 4.1ms preprocess, 174.1ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1500.jpg\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 bus, 1 truck, 171.7ms\n",
            "Speed: 4.4ms preprocess, 171.7ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1530.jpg\n",
            "\n",
            "0: 384x640 2 persons, 3 buss, 1 truck, 1 clock, 178.1ms\n",
            "Speed: 4.8ms preprocess, 178.1ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1560.jpg\n",
            "\n",
            "0: 384x640 14 persons, 1 bus, 2 tvs, 174.3ms\n",
            "Speed: 4.4ms preprocess, 174.3ms inference, 34.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1590.jpg\n",
            "\n",
            "0: 384x640 1 person, 174.8ms\n",
            "Speed: 4.2ms preprocess, 174.8ms inference, 51.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1620.jpg\n",
            "\n",
            "0: 384x640 3 persons, 172.8ms\n",
            "Speed: 4.6ms preprocess, 172.8ms inference, 51.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1650.jpg\n",
            "\n",
            "0: 384x640 4 persons, 175.9ms\n",
            "Speed: 4.4ms preprocess, 175.9ms inference, 41.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1680.jpg\n",
            "\n",
            "0: 384x640 3 persons, 170.7ms\n",
            "Speed: 4.5ms preprocess, 170.7ms inference, 24.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1710.jpg\n",
            "\n",
            "0: 384x640 3 persons, 176.6ms\n",
            "Speed: 4.6ms preprocess, 176.6ms inference, 28.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1740.jpg\n",
            "\n",
            "0: 384x640 3 persons, 177.1ms\n",
            "Speed: 4.5ms preprocess, 177.1ms inference, 28.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1770.jpg\n",
            "\n",
            "0: 384x640 4 persons, 172.0ms\n",
            "Speed: 4.7ms preprocess, 172.0ms inference, 34.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1800.jpg\n",
            "\n",
            "0: 384x640 6 persons, 177.4ms\n",
            "Speed: 4.1ms preprocess, 177.4ms inference, 34.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1830.jpg\n",
            "\n",
            "0: 384x640 6 persons, 186.0ms\n",
            "Speed: 4.2ms preprocess, 186.0ms inference, 27.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1860.jpg\n",
            "\n",
            "0: 384x640 5 persons, 173.5ms\n",
            "Speed: 4.7ms preprocess, 173.5ms inference, 31.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1890.jpg\n",
            "\n",
            "0: 384x640 5 persons, 1 traffic light, 184.6ms\n",
            "Speed: 4.3ms preprocess, 184.6ms inference, 37.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1920.jpg\n",
            "\n",
            "0: 384x640 5 persons, 1 traffic light, 174.5ms\n",
            "Speed: 4.6ms preprocess, 174.5ms inference, 74.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1950.jpg\n",
            "\n",
            "0: 384x640 3 persons, 1 traffic light, 278.9ms\n",
            "Speed: 4.4ms preprocess, 278.9ms inference, 49.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_1980.jpg\n",
            "\n",
            "0: 384x640 4 persons, 275.7ms\n",
            "Speed: 4.4ms preprocess, 275.7ms inference, 42.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2010.jpg\n",
            "\n",
            "0: 384x640 4 persons, 273.1ms\n",
            "Speed: 4.5ms preprocess, 273.1ms inference, 61.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2040.jpg\n",
            "\n",
            "0: 384x640 5 persons, 329.7ms\n",
            "Speed: 5.0ms preprocess, 329.7ms inference, 82.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2070.jpg\n",
            "\n",
            "0: 384x640 4 persons, 178.8ms\n",
            "Speed: 4.2ms preprocess, 178.8ms inference, 34.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2100.jpg\n",
            "\n",
            "0: 384x640 6 persons, 177.2ms\n",
            "Speed: 5.8ms preprocess, 177.2ms inference, 41.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2130.jpg\n",
            "\n",
            "0: 384x640 6 persons, 176.5ms\n",
            "Speed: 4.6ms preprocess, 176.5ms inference, 36.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2160.jpg\n",
            "\n",
            "0: 384x640 5 persons, 178.5ms\n",
            "Speed: 4.4ms preprocess, 178.5ms inference, 34.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2190.jpg\n",
            "\n",
            "0: 384x640 5 persons, 177.0ms\n",
            "Speed: 5.4ms preprocess, 177.0ms inference, 30.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2220.jpg\n",
            "\n",
            "0: 384x640 5 persons, 193.2ms\n",
            "Speed: 4.3ms preprocess, 193.2ms inference, 36.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2250.jpg\n",
            "\n",
            "0: 384x640 5 persons, 179.4ms\n",
            "Speed: 4.2ms preprocess, 179.4ms inference, 50.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2280.jpg\n",
            "\n",
            "0: 384x640 5 persons, 193.6ms\n",
            "Speed: 4.6ms preprocess, 193.6ms inference, 37.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2310.jpg\n",
            "\n",
            "0: 384x640 5 persons, 177.6ms\n",
            "Speed: 4.3ms preprocess, 177.6ms inference, 30.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2340.jpg\n",
            "\n",
            "0: 384x640 5 persons, 194.4ms\n",
            "Speed: 4.7ms preprocess, 194.4ms inference, 28.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2370.jpg\n",
            "\n",
            "0: 384x640 5 persons, 176.7ms\n",
            "Speed: 4.5ms preprocess, 176.7ms inference, 52.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2400.jpg\n",
            "\n",
            "0: 384x640 5 persons, 184.7ms\n",
            "Speed: 4.4ms preprocess, 184.7ms inference, 50.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2430.jpg\n",
            "\n",
            "0: 384x640 6 persons, 180.7ms\n",
            "Speed: 5.5ms preprocess, 180.7ms inference, 67.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2460.jpg\n",
            "\n",
            "0: 384x640 6 persons, 188.7ms\n",
            "Speed: 4.5ms preprocess, 188.7ms inference, 68.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2490.jpg\n",
            "\n",
            "0: 384x640 6 persons, 175.5ms\n",
            "Speed: 4.3ms preprocess, 175.5ms inference, 66.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2520.jpg\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 191.7ms\n",
            "Speed: 4.4ms preprocess, 191.7ms inference, 49.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2550.jpg\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 180.0ms\n",
            "Speed: 4.2ms preprocess, 180.0ms inference, 72.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2580.jpg\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 187.8ms\n",
            "Speed: 4.1ms preprocess, 187.8ms inference, 77.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2610.jpg\n",
            "\n",
            "0: 384x640 1 person, 174.3ms\n",
            "Speed: 4.3ms preprocess, 174.3ms inference, 71.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2640.jpg\n",
            "\n",
            "0: 384x640 16 persons, 6 cars, 1 bus, 1 truck, 243.2ms\n",
            "Speed: 4.3ms preprocess, 243.2ms inference, 82.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2670.jpg\n",
            "\n",
            "0: 384x640 15 persons, 7 cars, 1 bus, 1 umbrella, 282.5ms\n",
            "Speed: 4.4ms preprocess, 282.5ms inference, 82.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2700.jpg\n",
            "\n",
            "0: 384x640 5 persons, 7 cars, 1 bus, 292.3ms\n",
            "Speed: 4.5ms preprocess, 292.3ms inference, 44.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2730.jpg\n",
            "\n",
            "0: 384x640 11 persons, 3 cars, 1 truck, 304.2ms\n",
            "Speed: 4.1ms preprocess, 304.2ms inference, 50.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2760.jpg\n",
            "\n",
            "0: 384x640 1 car, 175.0ms\n",
            "Speed: 4.2ms preprocess, 175.0ms inference, 37.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2790.jpg\n",
            "\n",
            "0: 384x640 1 person, 1 car, 180.0ms\n",
            "Speed: 4.5ms preprocess, 180.0ms inference, 48.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2820.jpg\n",
            "\n",
            "0: 384x640 1 person, 175.0ms\n",
            "Speed: 4.2ms preprocess, 175.0ms inference, 24.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2850.jpg\n",
            "\n",
            "0: 384x640 1 person, 187.0ms\n",
            "Speed: 4.5ms preprocess, 187.0ms inference, 40.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2880.jpg\n",
            "\n",
            "0: 384x640 1 person, 174.3ms\n",
            "Speed: 4.4ms preprocess, 174.3ms inference, 48.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2910.jpg\n",
            "\n",
            "0: 384x640 1 person, 184.3ms\n",
            "Speed: 4.2ms preprocess, 184.3ms inference, 73.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2940.jpg\n",
            "\n",
            "0: 384x640 1 car, 177.2ms\n",
            "Speed: 4.5ms preprocess, 177.2ms inference, 72.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_2970.jpg\n",
            "\n",
            "0: 384x640 1 car, 188.7ms\n",
            "Speed: 4.5ms preprocess, 188.7ms inference, 77.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3000.jpg\n",
            "\n",
            "0: 384x640 1 person, 183.3ms\n",
            "Speed: 4.4ms preprocess, 183.3ms inference, 42.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3030.jpg\n",
            "\n",
            "0: 384x640 2 cars, 180.8ms\n",
            "Speed: 4.3ms preprocess, 180.8ms inference, 89.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3060.jpg\n",
            "\n",
            "0: 384x640 1 car, 175.5ms\n",
            "Speed: 4.1ms preprocess, 175.5ms inference, 72.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3090.jpg\n",
            "\n",
            "0: 384x640 3 cars, 176.4ms\n",
            "Speed: 4.0ms preprocess, 176.4ms inference, 34.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3120.jpg\n",
            "\n",
            "0: 384x640 2 cars, 308.1ms\n",
            "Speed: 4.1ms preprocess, 308.1ms inference, 48.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3150.jpg\n",
            "\n",
            "0: 384x640 2 cars, 214.9ms\n",
            "Speed: 4.7ms preprocess, 214.9ms inference, 41.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3180.jpg\n",
            "\n",
            "0: 384x640 2 cars, 208.7ms\n",
            "Speed: 4.5ms preprocess, 208.7ms inference, 36.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3210.jpg\n",
            "\n",
            "0: 384x640 1 car, 200.9ms\n",
            "Speed: 4.2ms preprocess, 200.9ms inference, 46.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3240.jpg\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 208.6ms\n",
            "Speed: 4.9ms preprocess, 208.6ms inference, 33.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3270.jpg\n",
            "\n",
            "0: 384x640 1 person, 1 car, 248.8ms\n",
            "Speed: 4.5ms preprocess, 248.8ms inference, 60.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3300.jpg\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 409.2ms\n",
            "Speed: 4.7ms preprocess, 409.2ms inference, 112.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3330.jpg\n",
            "\n",
            "0: 384x640 2 cars, 828.7ms\n",
            "Speed: 26.5ms preprocess, 828.7ms inference, 230.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3360.jpg\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1015.3ms\n",
            "Speed: 11.7ms preprocess, 1015.3ms inference, 163.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3390.jpg\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 294.0ms\n",
            "Speed: 4.6ms preprocess, 294.0ms inference, 25.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3420.jpg\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 274.7ms\n",
            "Speed: 4.5ms preprocess, 274.7ms inference, 38.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3450.jpg\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 truck, 187.2ms\n",
            "Speed: 4.6ms preprocess, 187.2ms inference, 32.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3480.jpg\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 182.6ms\n",
            "Speed: 4.2ms preprocess, 182.6ms inference, 38.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3510.jpg\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 truck, 182.7ms\n",
            "Speed: 4.9ms preprocess, 182.7ms inference, 38.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3540.jpg\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 truck, 177.9ms\n",
            "Speed: 4.2ms preprocess, 177.9ms inference, 52.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3570.jpg\n",
            "\n",
            "0: 384x640 1 person, 1 truck, 182.5ms\n",
            "Speed: 4.3ms preprocess, 182.5ms inference, 62.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3600.jpg\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 truck, 189.9ms\n",
            "Speed: 3.6ms preprocess, 189.9ms inference, 45.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3630.jpg\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 truck, 176.0ms\n",
            "Speed: 4.2ms preprocess, 176.0ms inference, 68.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3660.jpg\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 truck, 192.8ms\n",
            "Speed: 4.2ms preprocess, 192.8ms inference, 67.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3690.jpg\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 truck, 178.8ms\n",
            "Speed: 4.8ms preprocess, 178.8ms inference, 49.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3720.jpg\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 truck, 179.6ms\n",
            "Speed: 4.3ms preprocess, 179.6ms inference, 64.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3750.jpg\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 truck, 173.9ms\n",
            "Speed: 4.3ms preprocess, 173.9ms inference, 54.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3780.jpg\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 truck, 180.2ms\n",
            "Speed: 4.6ms preprocess, 180.2ms inference, 51.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3810.jpg\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 truck, 179.6ms\n",
            "Speed: 4.4ms preprocess, 179.6ms inference, 68.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3840.jpg\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 174.9ms\n",
            "Speed: 4.2ms preprocess, 174.9ms inference, 82.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3870.jpg\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 184.7ms\n",
            "Speed: 4.2ms preprocess, 184.7ms inference, 49.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3900.jpg\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 210.1ms\n",
            "Speed: 4.3ms preprocess, 210.1ms inference, 155.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3930.jpg\n",
            "\n",
            "0: 384x640 1 person, 1 car, 276.3ms\n",
            "Speed: 4.3ms preprocess, 276.3ms inference, 139.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3960.jpg\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 296.4ms\n",
            "Speed: 4.6ms preprocess, 296.4ms inference, 155.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_3990.jpg\n",
            "\n",
            "0: 384x640 5 persons, 318.2ms\n",
            "Speed: 7.6ms preprocess, 318.2ms inference, 137.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_4020.jpg\n",
            "\n",
            "0: 384x640 3 persons, 186.0ms\n",
            "Speed: 4.5ms preprocess, 186.0ms inference, 102.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_420.jpg\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 177.1ms\n",
            "Speed: 4.2ms preprocess, 177.1ms inference, 49.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_450.jpg\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 180.3ms\n",
            "Speed: 4.1ms preprocess, 180.3ms inference, 38.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_480.jpg\n",
            "\n",
            "0: 384x640 3 persons, 175.0ms\n",
            "Speed: 4.6ms preprocess, 175.0ms inference, 73.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_510.jpg\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 178.2ms\n",
            "Speed: 4.9ms preprocess, 178.2ms inference, 72.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_540.jpg\n",
            "\n",
            "0: 384x640 1 truck, 175.3ms\n",
            "Speed: 4.4ms preprocess, 175.3ms inference, 43.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_570.jpg\n",
            "\n",
            "0: 384x640 1 truck, 189.6ms\n",
            "Speed: 4.2ms preprocess, 189.6ms inference, 61.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_600.jpg\n",
            "\n",
            "0: 384x640 1 car, 3 buss, 1 truck, 173.7ms\n",
            "Speed: 5.0ms preprocess, 173.7ms inference, 44.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_630.jpg\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 1 truck, 186.7ms\n",
            "Speed: 4.6ms preprocess, 186.7ms inference, 87.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_660.jpg\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 bus, 1 truck, 182.0ms\n",
            "Speed: 4.3ms preprocess, 182.0ms inference, 39.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_690.jpg\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 truck, 173.1ms\n",
            "Speed: 3.1ms preprocess, 173.1ms inference, 33.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_720.jpg\n",
            "\n",
            "0: 384x640 1 car, 3 buss, 1 truck, 187.4ms\n",
            "Speed: 4.7ms preprocess, 187.4ms inference, 32.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_750.jpg\n",
            "\n",
            "0: 384x640 1 car, 3 buss, 1 truck, 172.9ms\n",
            "Speed: 10.5ms preprocess, 172.9ms inference, 36.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_780.jpg\n",
            "\n",
            "0: 384x640 1 car, 3 buss, 1 truck, 182.9ms\n",
            "Speed: 4.8ms preprocess, 182.9ms inference, 39.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_810.jpg\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 1 truck, 177.2ms\n",
            "Speed: 4.5ms preprocess, 177.2ms inference, 68.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_840.jpg\n",
            "\n",
            "0: 384x640 5 cars, 2 buss, 1 truck, 188.2ms\n",
            "Speed: 4.5ms preprocess, 188.2ms inference, 47.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_870.jpg\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 1 truck, 186.0ms\n",
            "Speed: 4.7ms preprocess, 186.0ms inference, 47.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_900.jpg\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 bus, 183.6ms\n",
            "Speed: 4.3ms preprocess, 183.6ms inference, 49.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_930.jpg\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 187.9ms\n",
            "Speed: 4.9ms preprocess, 187.9ms inference, 58.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_960.jpg\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 273.5ms\n",
            "Speed: 4.4ms preprocess, 273.5ms inference, 71.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Processed: frame_990.jpg\n",
            "✅ Completed safety processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating new video with the implementation"
      ],
      "metadata": {
        "id": "vLBX4yNLKXYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "frames_dir = \"safety_processed_frames\"\n",
        "output_video = \"safety_processed_video.mp4\"\n",
        "\n",
        "# Get frame properties\n",
        "frame_files = sorted(os.listdir(frames_dir))\n",
        "first_frame = cv2.imread(os.path.join(frames_dir, frame_files[0]))\n",
        "height, width = first_frame.shape[:2]\n",
        "\n",
        "# Create video writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video, fourcc, 30, (width, height))\n",
        "\n",
        "# Add frames to video\n",
        "for frame_file in frame_files:\n",
        "    frame = cv2.imread(os.path.join(frames_dir, frame_file))\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()\n",
        "print(f\"✅ Created video: {output_video}\")\n",
        "\n",
        "# Download video (in Colab)\n",
        "from google.colab import files\n",
        "files.download(output_video)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "RcU4tB7xKZ9W",
        "outputId": "d11ae0ba-f4fa-46c5-c754-cdf291a38b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created video: safety_processed_video.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dc8912ce-9fd1-4322-acef-83b9bd625481\", \"safety_processed_video.mp4\", 140615955)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}